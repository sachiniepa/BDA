{
  "metadata": {
    "name": "Untitled Note 1",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\nfrom pyspark.sql.functions import split\nimport matplotlib.pyplot as plt\nfrom pyspark.sql.functions import trim\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n\ndf2 \u003d df.withColumn(\"Year\", split(col(\"date\"),\"-\").getItem(0)).withColumn(\"Month\",split(col(\"date\"),\"-\").getItem(1)).withColumn(\"Day\",split(col(\"date\"),\"-\").getItem(2)).withColumn(\"Date\",split(col(\"date\"),\"-\")).drop(\"date\")\ndf2.show(10)\ndf2.createOrReplaceTempView(\"matchesWithDateSplit\")\nsql2 \u003d spark.sql(\"SELECT Year FROM matchesWithDateSplit\")\nsql2.show(10)\ndf3 \u003d sql2.select(col(\u0027Year\u0027).cast(\u0027int\u0027))\npdf \u003d df3.toPandas()\npdf.hist(bins \u003d 150)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}