{
  "metadata": {
    "name": "part3",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n#Load the data in the csv file to the data frame.\ndf \u003d spark.read.format(\"csv\").option(\u0027header\u0027, \u0027true\u0027).load(\"/data/results.csv\")\ndf.show(20)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\ndf.toPandas()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\ndf.count()\ndf.columns\ndf.dtypes"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nfrom pyspark.sql.functions import col\n\ndf2 \u003d df.select(col(\u0027home_team\u0027), col(\u0027away_team\u0027), col(\u0027home_score\u0027).cast(\u0027int\u0027), col(\u0027away_score\u0027).cast(\u0027int\u0027), col(\u0027city\u0027), col(\u0027country\u0027))\ndf.show(10)\ndf2.show(10)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n#Data Preparation\n#import pyspark.sql.functions as F\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType\n\n\ndef set_Result(value):\n  if  value \u003c 0: \n      return \u0027DEFEAT\u0027\n  else:\n      if value \u003e 0:\n          return \u0027WIN\u0027\n      else:\n          return \u0027DRAW\u0027\n\ndf2.createOrReplaceTempView(\"initial_data\")\ndf3 \u003d spark.sql(\"Select *, (home_score-away_score) as Intm_result from initial_data\")\ndf3.show(10)\ndf4 \u003d df3.select(col(\u0027home_team\u0027),col(\u0027away_team\u0027), col(\u0027home_score\u0027).cast(\u0027int\u0027), col(\u0027away_score\u0027).cast(\u0027int\u0027), col(\u0027city\u0027), col(\u0027country\u0027), col(\u0027Intm_result\u0027).cast(\u0027int\u0027))\ndf4.printSchema()\ndf5 \u003d df4.withColumn(\u0027Id_New\u0027, when(df4.Intm_result \u003e 0,\u0027WIN\u0027).otherwise(when (df4.Intm_result \u003c 0, \u0027DEFEAT\u0027).otherwise(\u0027DRAW\u0027))).select(col(\u0027home_team\u0027), col(\u0027away_team\u0027), col(\u0027home_score\u0027).cast(\u0027int\u0027), col(\u0027away_score\u0027).cast(\u0027int\u0027), col(\u0027city\u0027), col(\u0027country\u0027), col(\u0027Intm_result\u0027).cast(\u0027int\u0027), col(\u0027Id_New\u0027).alias(\u0027Final_Result\u0027))\ndf5.show(20)\n#get_result \u003d F.udf(set_Result, StringType())\n#spark.udf.register(\"set_Result\", set_Result, IntegerType())\n#df5 \u003d df4.withColumn(\"Final_Result\", set_Result(col(\u0027Intm_result\u0027).cast(\u0027int\u0027)))\n#df5.show(10) "
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\ndf5.printSchema()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n#Encode string fields to get numeric data\n\nfrom pyspark.ml.feature import StringIndexer\n\ndf6 \u003d StringIndexer(inputCol\u003d\u0027home_team\u0027, outputCol\u003d\u0027home_team_numeric\u0027, handleInvalid\u003d\u0027keep\u0027).fit(df5).transform(df5)\ndf7 \u003d StringIndexer(inputCol\u003d\u0027away_team\u0027, outputCol\u003d\u0027away_team_numeric\u0027, handleInvalid\u003d\u0027keep\u0027).fit(df6).transform(df6)\ndf8 \u003d StringIndexer(inputCol\u003d\u0027city\u0027, outputCol\u003d\u0027city_numeric\u0027, handleInvalid\u003d\u0027keep\u0027).fit(df7).transform(df7)\ndf9 \u003d StringIndexer(inputCol\u003d\u0027country\u0027, outputCol\u003d\u0027country_numeric\u0027, handleInvalid\u003d\u0027keep\u0027).fit(df8).transform(df8)\ndf10 \u003d StringIndexer(inputCol\u003d\u0027Final_Result\u0027, outputCol\u003d\u0027Final_Result_numeric\u0027, handleInvalid\u003d\u0027keep\u0027).fit(df9).transform(df9)\ndf10.show(30)\n\ndf10.dtypes"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n#Removing the non-numeric columns from the data frame\n\nfrom functools import reduce\nfrom pyspark.sql import DataFrame\n\ndf11 \u003d reduce(DataFrame.drop, [\u0027home_team\u0027,\u0027away_team\u0027, \u0027city\u0027, \u0027country\u0027, \u0027Final_Result\u0027], df10)\ndf11.show(30)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nfrom pyspark.ml.feature import VectorAssembler\n\nrequired_features \u003d [\u0027home_team_numeric\u0027, \u0027away_team_numeric\u0027, \u0027city_numeric\u0027, \u0027country_numeric\u0027]\nassembler \u003d VectorAssembler(inputCols\u003drequired_features, outputCol\u003d\u0027features\u0027)\ntransformed_data \u003d assembler.transform(df11)\ntransformed_data.show(30)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n#Splitting the data in to training data(80%) and testing data(20%)\n(training_data, test_data) \u003d transformed_data.randomSplit([0.8,0.2])"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\nfrom pyspark.ml.classification import RandomForestClassifier\nrf \u003d RandomForestClassifier(labelCol\u003d\u0027Final_Result_numeric\u0027, featuresCol\u003d\u0027features\u0027, numTrees\u003d10, maxBins\u003d2020)\n#rf \u003d RandomForestClassifier(labelCol\u003d\"indexedLabel\", featuresCol\u003d\"indexedFeatures\", numTrees\u003d10)\nmodel \u003d rf.fit(training_data)\npredictions \u003d model.transform(test_data)\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n# Evaluate our model\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator \u003d MulticlassClassificationEvaluator(labelCol\u003d\u0027Final_Result_numeric\u0027, predictionCol\u003d\u0027prediction\u0027, metricName\u003d\u0027accuracy\u0027)\naccuracy \u003d evaluator.evaluate(predictions)\nprint(\u0027Test Accuracy \u003d \u0027, accuracy) "
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}